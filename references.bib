@article{agouti-2019,
  title = {Agouti: A platform for processing and archiving of camera trap images},
  author = {Jim Casaer and Tanja Milotic and Yorick Liefting and Peter Desmet and Patrick Jansen},
  year = {2019},
  journal = {Biodiversity Information Science and Standards},
  publisher = {Pensoft Publishers},
  volume = {3},
  number = {},
  pages = {e46690},
  doi = {10.3897/biss.3.46690},
  issn = {},
  url = {https://doi.org/10.3897/biss.3.46690},
  abstract = {Camera traps placed in the field, photograph warm-bodied animals that pass in front of an infrared sensor. The imagery represents a rich source of data on mammals larger than ~200 grams, providing information at the level of species and communities. Camera-trap surveys generate observations of specific mammals at a certain location and time, including photo evidence that can be evaluated by experts to map species distribution patterns. The imagery also provides information on the species composition of local communities, identifying which species co-occur and in what proportion. Moreover, the images contain information on activity patterns and other interesting aspects of animal behaviour. Because surveys can be standardized relatively easily, camera traps are well suited for documenting shifts in the behaviour, distribution and community composition, for example in response to climate and land-use change. Imagery from camera traps can thus serve as a baseline for subsequent surveys. In less than two decades, camera traps have become the standard tool for surveying mammals. They are simple to use and non-invasive, requiring no special permits. As a consequence they are widely used by professionals and hobbyists alike. Together, tens of thousands of users have the potential to form a huge sensor network. Unfortunately however, imagery and data collected are currently rarely integrated. Rather, they are lost at a massive scale. Users tend to retain only a subset of the photos and discard the rest. Or the material ends up on an external hard disk that will at some point fail or be erased as these scientific data tend to be used within the scope of specific projects. Very few of the wealth of material becomes available for scientific research and monitoring. Moreover, joint projects are rare and there is little coordination between camera-trap users. A solution to this problem is provided by Agouti, a platform for the organization, processing and storage of camera-trap imagery (www.agouti.eu). The aim of Agouti is, on the one hand, to standardize and facilitate collaborative camera-trap surveys, and on the other hand to compile and secure imagery and data for scientific research and monitoring, by encouraging users to share their material. Agouti provides an interface that allows users to collaborate on projects, organize and manage their surveys, upload and store imagery, and annotate images with species identifications and characteristics. Images can also be annotated through basic image recognition and crowd sourcing via a connection with the citizen science platform Zooniverse, which creates the potential to reach new audiences. Exporting data and imagery in the Camera Trap Metadata Standard (Forrester et al. 2016) will be supported in the near future. This will allow data to be archived outside of Agouti in research repositories such as Zenodo and by further mapping to Darwin Core to be made discoverable on the Global Biodiversity Information Facility (GBIF). Agouti provides both professionals and the public with a practical solution for retaining camera-trap surveys and simultaneously engages people in contributing data to science in a standardized and organized manner, to the benefit of science and conservation.},
  eprint = {https://doi.org/10.3897/biss.3.46690}
}
@article{alony-2020,
  title = {Online volunteering at DigiVol: an innovative crowd-sourcing approach for heritage tourism artefacts preservation},
  author = {Irit Alony and Debbie Haski-Leventhal and Leonie Lockstone-Binney and Kirsten Holmes and Lucas C. P. M. Meijs},
  year = {2020},
  journal = {Journal of Heritage Tourism},
  publisher = {Routledge},
  volume = {15},
  number = {1},
  pages = {14--26},
  doi = {10.1080/1743873X.2018.1557665},
  url = {https://doi.org/10.1080/1743873X.2018.1557665},
  eprint = {https://doi.org/10.1080/1743873X.2018.1557665}
}
@article{amatulli-2018,
  todo = {}
}
@article{bennett-2017,
  todo = {}
}
@article{berkel-2014,
  todo = {Berkel 2014}
}
@article{brides-2018,
  title = {The use of camera traps to identify individual colour-marked geese at a moulting site},
  author = {Kane Brides and Jon Middleton and Kevin Leighton and Adam Grogan},
  year = {2018},
  journal = {Ringing \& Migration},
  publisher = {Taylor & Francis},
  volume = {33},
  number = {1},
  pages = {19--22},
  doi = {10.1080/03078698.2018.1525194},
  url = {https://doi.org/10.1080/03078698.2018.1525194},
  eprint = {https://doi.org/10.1080/03078698.2018.1525194}
}
@article{buchhorn-2019,
  todo = {}
}
@article{burton-2015,
  todo = {Burton AC, Neilson E, Moreira D, Ladle A, Steenweg R, Fisher JT, et al. (2015) Wildlife camera trapping: a review and recommendations for linking surveys to ecological processes. J. Appl. Ecol., 52, 675–685.}
}
@article{bradley-2017,
  todo = {Bradley S (2017) MammalWeb - Participant guided development of a generalised citizen science web platform. https://edshare.soton.ac.uk/18337/}
}
@article{cadman-2014,
  todo = {Cadman M, González-Talaván A (eds.) (2014) Publishing Camera Trap Data, a Best Practice Guide. Contributed by Athreya V, Chavan V, Ghosh M, Hanssen F, Harihar A, Hirsch T, Lindgaard A, Mathur VB, Mehlum F, Pandav B, Talukdar G, Vang R. Copenhagen: Global Biodiversity Information Facility. Available online at http://www.gbif.org/orc/?doc_id=6045.}
}
@article{camelot,
  todo = {}
}
@article{camerabase,
  todo = {TCameraBase https://www.atrium-biodiversity.org/tools/camerabase/}
}
@article{cameratrap-manager,
  todo = {Cameratrap Manager}
}
@article{caravaggi-2020,
  todo = {}
}
@article{chapman-1927,
  todo = {}
}
@article{chapman-2020,
  todo = {Chapman AD, Wieczorek JR (2020) Georeferencing Best Practices. Copenhagen: GBIF Secretariat. https://doi.org/10.15468/doc-gg7h-s853}
}
@article{clements-2022,
  todo = {Clements JF, Schulenberg TS, Iliff MJ, Fredericks TA, Gerbracht JA, Lepage D, et al. (2022) The eBird/Clements checklist of Birds of the World: v2022. Downloaded from https://www.birds.cornell.edu/clementschecklist/download/}
}
@misc{col-2023,
  title = {Catalogue of Life Checklist},
  author = {{Bánki}, {Olaf} and {Roskov}, {Yury} and {Döring}, {Markus} and {Ower}, {Geoff} and {Vandepitte}, {Leen} and {Hobern}, {Donald} and {Remsen}, {David} and {Schalk}, {Peter} and {DeWalt}, {R. Edward} and {Keping}, {Ma} and {Miller}, {Joe} and {Orrell}, {Thomas} and {Aalbu}, {Rolf} and {Abbott}, {John} and {Adlard}, {Robert} and {Adriaenssens}, {Evelien M.} and {Aedo}, {Carlos} and {Aescht}, {E.} and {Akkari}, {Nesrine} and {Alexander}, {Sara} and {Alfenas-Zerbini}, {Poliane} and {Alonso-Zarazaga}, {Miguel A.} and {Altenburger}, {Katrin} and {Alvarez}, {Belinda} and {Alvarez}, {Fernando} and {Anderson}, {Gary} and {Andrella}, {Giovani Carlos} and {Antić}, {Dragan Z.} and {Antonietto}, {Lucas Silveira} and {Arango}, {Claudia} and {Artois}, {Tom} and {Arvanitidis}, {Christos} and {Atahuachi Burgos}, {Margoth} and {Atkinson}, {Stephen} and {Atwood}, {John J.} and {Auffenberg}, {Kurt} and {Bagnatori Sartori}, {Ângela Lúcia} and {Bailly}, {Nicolas} and {Baixeras}, {Joaquín} and {Baker}, {Edward} and {Balan}, {Anoop} and {Bamber}, {Roger} and {Bandesha}, {Farida} and {Bandyopadhyay}, {Subir} and {Bank}, {Ruud} and {Barber}, {Anthony} and {Barber-James}, {H.} and {Barbosa}, {Joao Paulo} and {Barbosa Pinto}, {Rafael} and {Barrett}, {Russell} and {Bartolozzi}, {L.} and {Bartsch}, {I.} and {Beccaloni}, {George W} and {Bellamy}, {C.L.} and {Bellan-Santini}, {Denise} and {Bellinger}, {P.F.} and {Ben-Dov}, {Yair} and {Bernot}, {James} and {Bezerra}, {Tania Nara} and {Bieler}, {Rüdiger} and {Bitner}, {Maria Aleksandra} and {Blasco-Costa}, {Isabel} and {Boatwright}, {James S.} and {Bock}, {Phil} and {Bonato}, {Lucio} and {Borges}, {Leonardo M.} and {Bota-Sierra}, {Cornelio} and {Bouchard}, {Patrice} and {Bouchet}, {Philippe} and {Bourgoin}, {T.} and {Boury-Esnault}, {Nicole} and {Bouzan}, {Rodrigo} and {Boxshall}, {Geoff} and {Boyko}, {Christopher} and {Brandão}, {Simone} and {Braun}, {Holger} and {Bray}, {Rod} and {Brinda}, {John C.} and {Brock}, {Paul D} and {Broich}, {Steven L.} and {Bronstein}, {Omri} and {Brown}, {John} and {Bruce}, {Niel} and {Brullo}, {Savatore} and {Bruneau}, {Anne} and {Bueno-Villegas}, {Julian} and {Burckhardt}, {Daniel} and {Bush}, {Louise} and {Böttger-Schnack}, {Ruth} and {Büscher}, {Thies} and {Błażewicz-Paszkowycz}, {Magdalena} and {Cairns}, {Stephen} and {Calonje}, {Michael} and {Camilo de Oliveira}, {João Paulo} and {Carballo}, {José Luis} and {Cardinal-McTeague}, {Warren} and {Cardoso}, {Domingos} and {Cardoso}, {Lilian} and {Carrera-Parra}, {Luis} and {Castilho}, {R.C.} and {Castro Silva}, {Isabella C.} and {Catalano}, {Sarah} and {Cervantes}, {Angélica} and {Chatrou}, {L.W.} and {Chevillotte}, {Herve} and {Choo}, {Le Min} and {Christiansen}, {K.A.} and {Cianferoni}, {F.} and {Cigliano}, {María Marta} and {Clarke}, {Ruth} and {Cobra e Monteiro}, {Thiago} and {Collins}, {Allen} and {Collins}, {Katie} and {Compton}, {James} and {Consorti}, {Lorenzo} and {Copilaș-Ciocianu}, {Denis} and {Corbari}, {Laure} and {Cordeiro}, {Ralf} and {CoreoideaSF Team} and {Cornils}, {Astrid} and {Costa Corgosinho}, {Paulo Henrique} and {Costello}, {Mark} and {Crameri}, {Simon} and {Cruz-López}, {Jesus A.} and {Culham}, {A.} and {Cárdenas}, {Paco} and {Daly}, {Meg} and {Daneliya}, {Mikhail} and {Dauvin}, {Jean-Claude} and {Davie}, {Peter} and {Davison}, {Andrew J.} and {De Broyer}, {Claude} and {De Lima}, {Haroldo C.} and {De Prins}, {Jurate} and {De Prins}, {Willy} and {De la Estrella}, {Manuel} and {DeSalle}, {Rob} and {Decker}, {Peter} and {Decock}, {Wim} and {Deem}, {Lesley S} and {Defaye}, {Danielle} and {Dekker}, {Henk} and {Delgado-Salinas}, {Alfonso} and {Deliry}, {Cyrille} and {Dellapé}, {Pablo M} and {Dempsey}, {Donald M.} and {Den Heyer}, {J.} and {Deprez}, {Tim} and {Desiderato}, {Andrea} and {Di Capua}, {Iole} and {Dijkstra}, {Klaas-Douwe} and {Dippenaar}, {Susan} and {Dmitriev}, {D.A.} and {Dohrmann}, {Martin} and {Doner}, {Stacy} and {Dorado}, {Óscar} and {Dorkeld}, {Franck} and {Downey}, {Rachel} and {Duan}, {Lei} and {Ducarme}, {Frédéric} and {Dutilh}, {Bas E.} and {Díaz}, {Maria-Cristina} and {Eades}, {David C} and {Egan}, {Ashley N.} and {Eibye-Jacobsen}, {Danny} and {Eisendle}, {Ursula} and {Eitel}, {Michael} and {El Nagar}, {Aliya} and {Emig}, {Christian} and {Emig}, {Christian C.} and {Engel}, {Michael S.} and {Enghoff}, {Henrik} and {Evans}, {G.A.} and {Evenhuis}, {Neal L} and {Faber}, {Marien} and {Falcão}, {Marcus} and {Farjon}, {A.} and {Farruggia}, {Frank} and {Fauchald}, {Kristian} and {Fautin}, {Daphne} and {Favret}, {Colin} and {Fernández-Rodríguez}, {Vanessa} and {Figueroa}, {Diego} and {Fišer}, {Cene} and {Forró}, {L.} and {Forstner}, {Martina} and {Fortuna-Perez}, {Ana Paula} and {Francis}, {Ardath} and {Fritsch}, {Peter} and {Froese}, {Rainer} and {Fuchs}, {Anne} and {Fujimoto}, {Shinta} and {Furuya}, {Hidetaka} and {Gagnon}, {Edeline} and {Garcia-Alvarez}, {Oscar} and {García}, {María Laura} and {Gardner}, {M.} and {Garic}, {Rade} and {Garnett}, {Stephen} and {Gasca}, {Rebeca} and {Gattolliat}, {J.-L.} and {Gaviria-Melo}, {Santiago} and {Gerken}, {Sarah} and {Gibson}, {David} and {Gibson}, {Raymond} and {Gielis}, {Cees} and {Gilligan}, {Todd} and {Giribet}, {Gonzalo} and {Gittenberger}, {Arjan} and {Giusso del Galdo}, {Gian Pietro} and {Glasby}, {Christopher} and {Glover}, {Adrian G.} and {Godoy}, {Miguel Ángel} and {Gofas}, {Serge} and {Goncharov}, {Mikhail} and {Gondim}, {Anne Isabelley} and {Goodwin}, {Claire} and {Govaerts}, {Rafaël} and {Grabowski}, {Michal} and {Granado}, {Alexia de A.} and {Gray}, {Alex} and {Gregório}, {Bernarda de Souza} and {Grether}, {Rosaura} and {Grimaldi}, {David A.} and {Gross}, {Onno} and {Grun}, {Tobias B.} and {Guerra-García}, {José Manuel} and {Guglielmone}, {Alberto} and {Guilbert}, {E.} and {Gusenleitner}, {Josef} and {Gómez-Noguera}, {Samuel Enrique} and {Haas}, {Fabian} and {Hadfield}, {Kerry A.} and {Hajdu}, {Eduardo} and {Harrach}, {Balázs} and {Harris}, {Leslie} and {Harrison}, {Robert L.} and {Hassler}, {Michael} and {Hayward}, {Bruce W.} and {Heads}, {Sam W} and {Hendrickson}, {R. Curtis} and {Hendrycks}, {Ed} and {Henry}, {Thomas J} and {Herbert}, {Dai} and {Hernandes}, {F.A.} and {Hernandez}, {Francisco} and {Hernández-Crespo}, {Juan Carlos} and {Herrera Bachiller}, {Alfonso} and {Hine}, {Adrian} and {Hirsch}, {Hannah} and {Ho}, {Ju-shey} and {Hodda}, {Mike} and {Hodson}, {Alicia} and {Hoeksema}, {Bert} and {Hoenemann}, {Mario} and {Holovachov}, {Oleksandr} and {Holstein}, {J.} and {Hooge}, {Matthew} and {Hooper}, {John} and {Hopkins}, {Heidi} and {Horak}, {Ivan} and {Horton}, {Tammy} and {Hosoya}, {Tsuyoshi} and {Houart}, {Roland} and {Hošek}, {Jirí} and {Hughes}, {Lauren} and {Huijbers}, {Chantal} and {Häuser}, {C.} and {Iniesta}, {Luiz Felipe Moretti} and {Ivanenko}, {Viatcheslav (Slava)} and {Janssen}, {Ronald} and {Janssens}, {F.} and {Jaume}, {Damià} and {Javadi}, {Firouzeh} and {Jazdzewski}, {Krzysztof} and {Johnson}, {Kevin P} and {Jordão}, {Lucas} and {Junglen}, {Sandra} and {Jóźwiak}, {Piotr} and {Kabat}, {Alan} and {Kamiński}, {Marcin Jan} and {Kanda}, {Kojun} and {Kantor}, {Yuri} and {Karanovic}, {Ivana} and {Karapunar}, {Baran} and {Kathirithamby}, {Jeyaraney} and {Kelly}, {Michelle} and {Kim}, {Young-Hyo} and {King}, {Rachael} and {Kirk}, {Paul} and {Kitching}, {Ian} and {Klautau}, {Michelle} and {Klitgaard}, {Bente B.} and {Knowles}, {Nick J.} and {Koenemann}, {Stefan} and {Korovchinsky}, {N.M.} and {Kotov}, {A.} and {Kouwenberg}, {Juliana} and {Kovács}, {Zoltan} and {Kramina}, {Tatiana} and {Krapf}, {Andrea} and {Krapp-Schickel}, {Traudl} and {Kremenetskaia}, {Antonina} and {Krishna}, {Kumar} and {Krishna}, {Valerie} and {Kroh}, {Andreas} and {Kroupa}, {A.S.} and {Krupovic}, {Mart} and {Kuhn}, {Jens H.} and {Kury}, {Adriano B.} and {Kury}, {Milena S.} and {Kvaček}, {J.} and {Köhler}, {Frank} and {Lachenaud}, {Olivier} and {Lado}, {Carlos} and {Lambert}, {Amy J.} and {Lambert}, {Gretchen} and {Lana C. Atunes}, {Lorena} and {Lazarus}, {David} and {Le Coze}, {François} and {Le Roux}, {M. Marianne} and {LeCroy}, {Sara} and {Ledis Linares}, {José} and {Leduc}, {Daniel} and {Lee}, {Sangmi} and {Lefkowitz}, {Elliot J.} and {Lewis}, {Gwilym P.} and {Li}, {Shi-Jin} and {Li-Qiang}, {Ji} and {Lichtwardt}, {Robert (†)} and {Lim}, {Swee-Cheng} and {Lobanov}, {A.} and {Lohrmann}, {V.} and {Londoño-Mesa}, {Mario} and {Longhorn}, {Stuart J.} and {Lorenz}, {Wolfgang} and {Lowry}, {Jim} and {Lozano}, {Federico} and {Lujan-Toro}, {Beatriz E.} and {Lumen}, {Ryan} and {Lyal}, {Chris HC} and {Lyangouzov}, {I.} and {Lörz}, {Anne-Nina} and {Macklin}, {James A.} and {Madin}, {Larry} and {Maehr}, {Michael D} and {Magnien}, {Philippe} and {Mah}, {Christopher} and {Mal}, {Noel} and {Mamos}, {Tomasz} and {Manconi}, {Renata} and {Mansano}, {Vidal} and {Marek}, {Paul} and {Marshall}, {Bruce} and {Martin}, {Jon H.} and {Martin}, {Patrick} and {Martin}, {Sara L.} and {Martínez-Melo}, {Alejandra} and {Martínez-Muñoz}, {Carlos Alberto} and {Mashego}, {Kagiso S.} and {Maslin}, {Bruce} and {Mattapha}, {Sawai} and {McFadden}, {Catherine} and {McKamey}, {S.} and {McMurtry}, {J.A.} and {Medrano}, {Miguel Angel} and {Medvedev}, {S.} and {Mees}, {Jan} and {Mejía-Madrid}, {Hugo Harlan} and {Mendes}, {Amanda C.} and {Merrin}, {Kelly} and {Mesa}, {N.C.} and {Messing}, {Charles} and {Migeon}, {Alain} and {Miller}, {Douglas R} and {Mills}, {Claudia} and {Minelli}, {A.} and {Miskelly}, {Ashley} and {Mitchell}, {David} and {Mokievsky}, {Vadim} and {Molodtsova}, {Tina} and {Mongiardino Koch}, {Nicolas} and {Montenegro Valls}, {José Francisco} and {Mooi}, {Richard} and {Morandini}, {André} and {Moreira da Rocha}, {Rosana} and {Morrow}, {Christine} and {Moteetee}, {Annah} and {Murphy}, {Bruce} and {Mushegian}, {Arcady R.} and {Narita}, {J.P.Z.} and {Nealova}, {Lenka} and {Nery}, {Davi Galvão} and {Neu-Becker}, {U} and {Neubauer}, {Thomas A.} and {Neubert}, {Eike} and {Neuhaus}, {Birger} and {Newton}, {Alfred} and {Ng Kee Lin}, {Peter} and {Nguyen}, {Anh} and {Nibert}, {Max L.} and {Nicolson}, {Dave} and {Nielsen}, {Sven} and {Nijhof}, {Ard} and {Nishikawa}, {Teruaki} and {Norenburg}, {Jon} and {Noyes}, {John} and {O'Hara}, {Tim} and {Ochoa}, {R.} and {Ohashi}, {Hiroyoshi} and {Ohashi}, {Kazuaki} and {Oksanen}, {Hanna M.} and {Ollerenshaw}, {Justin} and {Oosterbroek}, {P.} and {Opresko}, {Dennis} and {Orton}, {Richard J.} and {Osborne}, {Roy} and {Osigus}, {Hans-Jürgen} and {Oswald}, {J.D.} and {Ota}, {Yuzo} and {Otte}, {Daniel} and {Ouvrard}, {David} and {Paleobiology Database contributors} and {Pandey}, {Arun} and {Pape}, {Thomas} and {Paulay}, {Gustav} and {Paulson}, {Dennis} and {Pauly}, {Daniel} and {Paxton}, {Hannelore} and {Pedram}, {Majid} and {Pennington}, {R. Toby} and {Pereira}, {Julia da Silva} and {Perez-Gelabert}, {Daniel} and {Petrusek}, {A.} and {Peña Santiago}, {Reyes} and {Phillipson}, {Pete} and {Piasecki}, {Wojciech} and {Picton}, {Bernard} and {Pinheiro}, {Ulisses} and {Pisera}, {Andrzej} and {Pitkin}, {Brian} and {Poore}, {Gary} and {Povydysh}, {Maria} and {Praxedes}, {Rayran Araújo} and {Pulawski}, {W.J.} and {Pyle}, {Richard} and {Páll-Gergely}, {Barna} and {Pérez-García}, {José Andrés} and {Půža}, {Vladimír} and {Rainer}, {H.} and {Rakotonirina}, {Nivohenintsoa} and {Ramos}, {Gustavo} and {Ranzato Filardi}, {Fabiana} and {Raz}, {Lauren} and {Read}, {Geoffrey} and {Rees}, {Tony} and {Reich}, {Mike} and {Reimer}, {James Davis} and {Rein}, {Jan Ove} and {Reip}, {Hans} and {Reuscher}, {Michael} and {Rewicz}, {Tomasz} and {Reynolds}, {John} and {Richling}, {Ira} and {Rius}, {Marc} and {Robertson}, {David L.} and {Robertson}, {Tim} and {Robinson}, {Gaden} and {Robinson}, {Gaden S (†)} and {Rodríguez}, {Estefania} and {Romani}, {Luigi} and {Rosenberg}, {Gary} and {Rubino}, {Luisa} and {Ruggiero}, {Michael} and {Ríos}, {Pilar} and {Rützler}, {Klaus} and {Sabanadzovic}, {Sead} and {Salazar-Vallejo}, {Sergio} and {Sanborn}, {A.} and {Sanjappa}, {Munivenkatappa} and {Santos}, {Stéfhanne Guimarães} and {Santos-Guerra}, {Arnoldo} and {Saraiva de Oliveira}, {Jessica} and {Sartori}, {M.} and {Sattler}, {Klaus} and {Saucède}, {Thomas} and {Schierwater}, {Bernd} and {Schilling}, {Steve} and {Schley}, {Rowan} and {Schmid-Egger}, {C.} and {Schmidt-Rhaesa}, {A.} and {Schneider}, {Simon} and {Schoolmeesters}, {Paul} and {Schorr}, {Martin} and {Schrire}, {Brian} and {Schuchert}, {Peter} and {Schuh}, {R.T.} and {Schönberg}, {Christine} and {Schütz Rodrigues}, {Rodrigo} and {Scoble}, {Malcolm} and {Segers}, {H.} and {Seijo}, {Guillermo} and {Seleme}, {Elidiene Priscila} and {Senna}, {André} and {Serejo}, {Cristiana} and {Sforzi}, {A.} and {Sharma}, {Jyotsna} and {Shear}, {William} and {Shenkar}, {Noa} and {Short}, {Megan} and {Siciński}, {Jacek} and {Siddell}, {Stuart G.} and {Siegel}, {Volker} and {Sierwald}, {Petra} and {Sigda}, {Lauren} and {Silva}, {E.S.} and {Silva Flores}, {Andréia} and {Silva de Carvalho}, {Catarina} and {Simmonds}, {Peter} and {Simmons}, {Elizabeth} and {Simon}, {Marcelo Fragomeni} and {Simonsen}, {Thomas} and {Simpson}, {Charles E.} and {Sirichamorn}, {Yotsawate} and {Smith}, {Aaron D.} and {Smith}, {Donald B.} and {Smith}, {Vincent S} and {Smol}, {Nicole} and {Soares Gissi}, {Danilo} and {Sokoloff}, {Dmitry} and {Soulier-Perkins}, {A.} and {South}, {Eric J.} and {Souza-Filho}, {Jesser F.} and {Spearman}, {Lauren} and {Spelda}, {Jörg} and {Steger}, {Jan} and {Steiner}, {A.} and {Stemme}, {Torben} and {Sterrer}, {Wolfgang} and {Stevenson}, {Dennis} and {Stiewe}, {Martin B D} and {Stirton}, {Charles H.} and {Stjernegaard Jeppesen}, {Thomas} and {Stoev}, {Pavel} and {Strand}, {Malin} and {Straub}, {Shannon} and {Stueber}, {G} and {Stöhr}, {Sabine} and {Subramaniam}, {Shweta} and {Suzuki}, {Nobuhiro} and {Suárez-Morales}, {Eduardo} and {Swalla}, {Billie} and {Swedo}, {Jacek} and {Szumik}, {Claudia} and {Sánchez-Ruiz}, {M.} and {Sørensen}, {Martin Vinther} and {Taiti}, {Stefano} and {Takiya}, {D.M.} and {Tandberg}, {Anne Helene} and {Tang}, {Danny} and {Tavakilian}, {Gerard} and {Taylor}, {John} and {Taylor}, {Kristian} and {Tchesunov}, {Alexei} and {Thessen}, {A.} and {Thomas}, {James Darwin} and {Thomas}, {P.} and {ThripsWiki} and {Thuesen}, {Erik} and {Thulin}, {Mats} and {Thurston}, {Mike} and {Thuy}, {Ben} and {Todaro}, {Antonio} and {Todd}, {Jonathan} and {Torke}, {Benjamin M.} and {Turiault}, {M.} and {Turon}, {Xavier} and {Tyler}, {Seth} and {Uetz}, {Peter} and {Ulmer}, {Jonah M.} and {Uribe-Palomino}, {Julian} and {Vacelet}, {Jean} and {Vachard}, {Daniel} and {Vader}, {Wim} and {Van Dooerslaer}, {Koenraad} and {Van der Burgt}, {Xander} and {Vandamme}, {Anne-Mieke} and {Vanhoorne}, {Bart} and {Vanreusel}, {Ann} and {Varsani}, {Arvind} and {Vatanparast}, {Mohammad} and {Venekey}, {Virág} and {Vinarski}, {Maxim} and {Vonk}, {Ronald} and {Vos}, {Chris} and {Väinölä}, {Risto} and {Walker}, {Peter J.} and {Walker-Smith}, {Genefor} and {Walter}, {T. Chad} and {Wambiji}, {Nina} and {Warwick}, {Suzanne} and {Watling}, {Les} and {Weaver}, {Haylee} and {Webb}, {J.} and {Welbourn}, {W.C.} and {Wesener}, {Thomas} and {Whipps}, {Christopher} and {White}, {Kristine} and {Wieneke}, {Ulrich} and {Wilding}, {Nicholas} and {Williams}, {Gary} and {Wilson}, {Annette J.G.} and {Wilson}, {Robin} and {Wing}, {Peter} and {Winitsky}, {Sophie} and {Wirth}, {Christopher C.} and {Wojciechowski}, {Martin} and {Woodman}, {Simon} and {World Spider Catalog} and {Xavier}, {Joana} and {Yesson}, {C.} and {Yi}, {Tingshuang} and {Yoder}, {Mathew} and {Yu}, {Dicky Sick Ki} and {Yunakov}, {N.} and {Zahniser}, {J.} and {Zanol}, {Joana} and {Zeidler}, {Wolfgang} and {Zerbini}, {Francisco Murilo} and {Zhang}, {Rong} and {Zhang}, {Z.Q.} and {Zhao}, {Zeng} and {Ziegler}, {Alexander} and {Zinetti}, {F.} and {Zullini}, {Aldo} and {de Moraes}, {G.J.} and {de Voogd}, {Nicole} and {ten Hove}, {Harry} and {ter Poorten}, {Jan Johan} and {van Haaren}, {Ton} and {van Nieukerken}, {E.J.} and {van Ofwegen}, {Leen} and {van Soest}, {Rob} and {Łobocka}, {Małgorzata} and {Şentürk}, {Ozan} and {ITIS} and {International Committee on Taxonomy of Viruses (ICTV)} and {Legume Phylogeny Working Group (LPWG)}},
  year = {2023},
  month = {5},
  publisher = {Catalogue of Life},
  address = {Leiden, Netherlands},
  doi = {10.48580/dfs6},
  issn = {2405-8858},
  url = {https://www.checklistbank.org/dataset/9893},
  version = {2023-05-15}
}
@article{cusack-2015,
  todo = {}
}
@article{datacite,
  todo = {datacite}
}
@article{delisle-2021,
  todo = {}
}
@article{dinerstein-2017,
  title = {An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm},
  author = {Dinerstein, Eric and Olson, David and Joshi, Anup and Vynne, Carly and Burgess, Neil D. and Wikramanayake, Eric and Hahn, Nathan and Palminteri, Suzanne and Hedao, Prashant and Noss, Reed and Hansen, Matt and Locke, Harvey and Ellis, Erle C and Jones, Benjamin and Barber, Charles Victor and Hayes, Randy and Kormos, Cyril and Martin, Vance and Crist, Eileen and Sechrest, Wes and Price, Lori and Baillie, Jonathan E. M. and Weeden, Don and Suckling, Kierán and Davis, Crystal and Sizer, Nigel and Moore, Rebecca and Thau, David and Birch, Tanya and Potapov, Peter and Turubanova, Svetlana and Tyukavina, Alexandra and de Souza, Nadia and Pintea, Lilian and Brito, José C. and Llewellyn, Othman A. and Miller, Anthony G. and Patzelt, Annette and Ghazanfar, Shahina A. and Timberlake, Jonathan and Klöser, Heinz and Shennan-Farpón, Yara and Kindt, Roeland and Lillesø, Jens-Peter Barnekow and van Breugel, Paulo and Graudal, Lars and Voge, Maianna and Al-Shammari, Khalaf F. and Saleem, Muhammad},
  year = {2017},
  month = {04},
  journal = {BioScience},
  volume = {67},
  number = {6},
  pages = {534--545},
  doi = {10.1093/biosci/bix014},
  issn = {0006-3568},
  url = {https://doi.org/10.1093/biosci/bix014},
  eprint = {https://academic.oup.com/bioscience/article-pdf/67/6/534/17644834/bix014.pdf}
}
@article{emammal-design,
  todo = {Study Design Recommendation for a Park. eMammal https://emammal.si.edu/about/study-design/park}
}
@article{eml-2015,
  todo = {Darwin Core vocabulary: EML agent role vocabulary. Available from: https://rs.gbif.org/vocabulary/gbif/agent_role.xml [2015-02-13]}
}
@article{eunis-habitat,
  todo = {EUNIS Habitat Classification, https://eunis.eea.europa.eu/habitats.jsp}
}
@article{fegraus-2011,
  title = {Data acquisition and management software for camera trap data: A case study from the TEAM Network},
  author = {Eric H. Fegraus and Kai Lin and Jorge A. Ahumada and Chaitan Baru and Sandeep Chandra and Choonhan Youn},
  year = {2011},
  journal = {Ecological Informatics},
  volume = {6},
  number = {6},
  pages = {345--353},
  doi = {https://doi.org/10.1016/j.ecoinf.2011.06.003},
  issn = {1574-9541},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954111000549},
  keywords = {Camera traps, Wildlife monitoring, Data acquisition and management software, Global monitoring network, Cyberinfrastructure},
  abstract = {Camera traps and the images they generate are becoming an essential tool for field biologists studying and monitoring terrestrial animals, in particular medium to large terrestrial mammals and birds. In the last fiveyears, camera traps have made the transition to digital technology, where these devices now produce hundreds of instantly available images per month and a large amount of ancillary metadata (e.g., date, time, temperature, image size, etc.). Despite this accelerated pace in the development of digital image capture, field biologists still lack adequate software solutions to process and manage the increasing amount of information in a cost efficient way. In this paper we describe a software system that we have developed, called DeskTEAM, to address this issue. DeskTEAM has been developed in the context of the Tropical Ecology Assessment and Monitoring Network (TEAM), a global network that monitors terrestrial vertebrates. We describe the software architecture and functionality and its utility in managing and processing large amounts of digital camera trap data collected throughout the global TEAM network. DeskTEAM incorporates software features and functionality that make it relevant to the broad camera trapping community. These include the ability to run the application locally on a laptop or desktop computer, without requiring an Internet connection, as well as the ability to run on multiple operating systems; an intuitive navigational user interface with multiple levels of detail (from individual images, to whole groups of images) which allows users to easily manage hundreds or thousands of images; ability to automatically extract EXIF and custom metadata information from digital images to increase standardization; availability of embedded taxonomic lists to allow users to easily tag images with species identities; and the ability to export data packages consisting of data, metadata and images in standardized formats so that they can be transferred to online data warehouses for easy archiving and dissemination. Lastly, building these software tools for wildlife scientists provides valuable lessons for the ecoinformatics community.}
}
@article{forrester-2016,
  todo = {Forrester T, O’Brien T, Fegraus E, Jansen PA, Palmer J, Kays R, et al. (2016). An open standard for camera trap data. Biodiversity Data Journal, 4, e10197.}
}
@article{forston-2012,
  todo = {Fortson L, Masters K, Nichol R, Borne K, Edmondson E, Lintott C,et al. (2012) Galaxy zoo: Morphological classification and citizen science. In Way MJ, Scargle JD, Ali KM, Srivastava AN (Eds.) Advances in machine learning and data mining for astronomy (pp. 213–236). Boca Raton, FL: CRC Press.}
}
@article{glover-2019,
  todo = {Glover & Kapfer 2019}
}
@article{gomez-villa-2017,
  title = {Towards automatic wild animal monitoring: Identification of animal species in camera-trap images using very deep convolutional neural networks},
  author = {Alexander {Gomez Villa} and Augusto Salazar and Francisco Vargas},
  year = {2017},
  journal = {Ecological Informatics},
  volume = {41},
  pages = {24--32},
  doi = {10.1016/j.ecoinf.2017.07.004},
  issn = {1574-9541},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954116302047},
  keywords = {Animal species recognition, Deep convolutional neural networks, Camera-trap, Snapshot Serengeti},
  abstract = {Non-intrusive monitoring of animals in the wild is possible using camera trapping networks. The cameras are triggered by sensors in order to disturb the animals as little as possible. This approach produces a high volume of data (in the order of thousands or millions of images) that demands laborious work to analyze both useless (incorrect detections, which are the most) and useful (images with presence of animals). In this work, we show that as soon as some obstacles are overcome, deep neural networks can cope with the problem of the automated species classification appropriately. As case of study, the most common 26 of 48 species from the Snapshot Serengeti (SSe) dataset were selected and the potential of the Very Deep Convolutional neural networks framework for the species identification task was analyzed. In the worst-case scenario (unbalanced training dataset containing empty images) the method reached 35.4% Top-1 and 60.4% Top-5 accuracy. For the best scenario (balanced dataset, images containing foreground animals only, and manually segmented) the accuracy reached a 88.9% Top-1 and 98.1% Top-5, respectively. To the best of our knowledge, this is the first published attempt on solving the automatic species recognition on the SSe dataset. In addition, a comparison with other approaches on a different dataset was carried out, showing that the architectures used in this work outperformed previous approaches. The limitations of the method, drawbacks, as well as new challenges in automatic camera-trap species classification are widely discussed.}
}
@article{green-2020,
  todo = {Green SE, Rees JP, Stephens PA, Hill RA, Giordano AJ (2020) Innovations in camera trapping technology and approaches: the integration of citizen science and artificial intelligence. Animals, 10, 132. https://doi.org/10.3390/ani10010132}
}
@article{groom-2018,
  todo = {Groom Q, De Smedt S, Verissimo Pereira N, Bogaerts A, Engledo H (2018) BISS, 2, e26803. https://doi.org/10.3897/biss.2.26803}
}
@article{guillera-2010,
  todo = {Guillera & Arroita 2010}
}
@article{hobbs-2017,
  todo = {Hobbs & Brehme 2017}
}
@article{hsing-2018,
  todo = {Hsing P, Bradley S, Kent VT, Hill RA, Smith GC, Whittingham MJ et al. (2018) Economical crowdsourcing for camera trap image classification. Remote Sensing in Ecology and Conservation, 4 (4), 361-374. https://doi.org/10.1002/rse2.84}
}
@article{iucn-habitat,
  todo = {IUCN Habitat Classification, https://www.iucnredlist.org/resources/habitat-classification-scheme}
}
@article{jones-2009,
  todo = {Jones KE, Bielby J, Cardillo M, Fritz SA, O’Dell J, Orme DL et al. (2009) PanTHERIA: a species-level database of life history, ecology, and geography of extant and recently extinct mammals. Ecology, 90 (9): 2648-2648. https://doi.org/10.1890/08-1494.1}
}
@article{jung-2020,
  todo = {}
}
@article{kays-2020,
  todo = {Kays R, Arbogast BS, Baker-Whatton M, Beirne C, Boone HM, Bowler M, Burneo SF, Cove MV, Ding P, Espinosa S, Gonçalves ALS, Hansen CP, Jansen PA, Kolowski JM, Knowles TW, Lima MGM, Millspaugh J, McShea WJ, Pacifici K, et al. (2020) An empirical of camera trap study design: How many long and when? Methods in Ecology and Evolution. 11(6), 700-713. https://doi.org/10.1111/2041-210X.13370}
}
@article{kolowski-2017,
  todo = {Kolowski JM, Forrester TD (2017) Camera trap placement and the potential for bias due to trails and other features. PloS one, 12(10), e0186679. https://doi.org/10.1371/journal.pone.0186679}
}
@article{kucera-2011,
  todo = {}
}
@article{lamelas-2020,
  todo = {Lamelas-Lopez L, Pardavila X, Amorim IR, Borges P (2020) Wildlife inventory from camera-trapping surveys in the Azores (Pico and Terceira islands). Biodiversity data journal, 8, e47865. https://doi.org/10.3897/BDJ.8.e47865}
}
@article{law-2018,
  todo = {}
}
@article{mackenzie-2005,
  todo = {}
}
@article{mcintyre-2020,
  todo = {}
}
@article{meek-2014,
  todo = {Meek P, Fleming P, Ballard G, Banks P, Claridge A, Sanderson J, et al. (eds.) (2014). Camera Trapping: Wildlife Management and Research. Csiro Publishing.}
}
@article{meek-2020,
  todo = {}
}
@article{newkirk-2016,
  todo = {Newkirk ES (2016) CPW Photo Database. Colorado Parks and Wildlife, Fort Collins, Colorado, USA. http://cpw.state.co.us/learn/Pages/ResearchMammalsSoftware.aspx}
}
@article{norouzzadeh-2020,
  title = {A deep active learning system for species identification and counting in camera trap images},
  author = {Norouzzadeh, Mohammad Sadegh and Morris, Dan and Beery, Sara and Joshi, Neel and Jojic, Nebojsa and Clune, Jeff},
  year = {2021},
  journal = {Methods in Ecology and Evolution},
  volume = {12},
  number = {1},
  pages = {150--161},
  doi = {10.1111/2041-210X.13504},
  url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13504},
  keywords = {active learning, camera trap images, computer vision, deep learning, deep neural networks},
  eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13504},
  abstract = {Abstract A typical camera trap survey may produce millions of images that require slow, expensive manual review. Consequently, critical conservation questions may be answered too slowly to support decision-making. Recent studies demonstrated the potential for computer vision to dramatically increase efficiency in image-based biodiversity surveys; however, the literature has focused on projects with a large set of labelled training images, and hence many projects with a smaller set of labelled images cannot benefit from existing machine learning techniques. Furthermore, even sizable projects have struggled to adopt computer vision methods because classification models overfit to specific image backgrounds (i.e. camera locations). In this paper, we combine the power of machine intelligence and human intelligence via a novel active learning system to minimize the manual work required to train a computer vision model. Furthermore, we utilize object detection models and transfer learning to prevent overfitting to camera locations. To our knowledge, this is the first work to apply an active learning approach to camera trap images. Our proposed scheme can match state-of-the-art accuracy on a 3.2 million image dataset with as few as 14,100 manual labels, which means decreasing manual labelling effort by over 99.5\%. Our trained models are also less dependent on background pixels, since they operate only on cropped regions around animals. The proposed active deep learning scheme can significantly reduce the manual labour required to extract information from camera trap images. Automation of information extraction will not only benefit existing camera trap projects, but can also catalyse the deployment of larger camera trap arrays.}
}
@inproceedings{nguyen-2017,
  title = {Animal Recognition and Identification with Deep Convolutional Neural Networks for Automated Wildlife Monitoring},
  author = {Nguyen, Hung and Maclagan, Sarah J. and Nguyen, Tu Dinh and Nguyen, Thin and Flemons, Paul and Andrews, Kylie and Ritchie, Euan G. and Phung, Dinh},
  year = {2017},
  booktitle = {2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
  volume = {},
  number = {},
  pages = {40--49},
  doi = {10.1109/DSAA.2017.31}
}
@article{obrien-2010,
  todo = {}
}
@article{oconnell-2011,
  todo = {O’Connell AF, Nichols JD, Karanth KU (2011) Camera Traps in Animal Ecology: Methods and Analyses. Springer, New York.}
}
@article{oconnor-2017,
  todo = {O'Connor KM, Nathan LR, Liberati MR, Tingley MW, Vokoun JC, Rittenhouse TAG (2017) Camera trap arrays improve detection probability of wildlife: Investigating study design considerations using an empirical dataset. PLoS ONE 12(4). e0175684. https://doi.org/10.1371/journal.pone.0175684}
}
@article{oliveira-2017,
  todo = {}
}
@article{price-tack-2016,
  title = {AnimalFinder: A semi-automated system for animal detection in time-lapse camera trap images},
  author = {Jennifer L. {Price Tack} and Brian S. West and Conor P. McGowan and Stephen S. Ditchkoff and Stanley J. Reeves and Allison C. Keever and James B. Grand},
  year = {2016},
  journal = {Ecological Informatics},
  volume = {36},
  pages = {145--151},
  doi = {10.1016/j.ecoinf.2016.11.003},
  issn = {1574-9541},
  url = {https://www.sciencedirect.com/science/article/pii/S1574954116301121},
  keywords = {Camera trap, Game camera, N-mixture model, Image processing, Wildlife monitoring, Animal detection},
  abstract = {Although the use of camera traps in wildlife management is well established, technologies to automate image processing have been much slower in development, despite their potential to drastically reduce personnel time and cost required to review photos. We developed AnimalFinder in MATLAB® to identify animal presence in time-lapse camera trap images by comparing individual photos to all images contained within the subset of images (i.e. photos from the same survey and site), with some manual processing required to remove false positives and collect other relevant data (species, sex, etc.). We tested AnimalFinder on a set of camera trap images and compared the presence/absence results with manual-only review with white-tailed deer (Odocoileus virginianus), wild pigs (Sus scrofa), and raccoons (Procyon lotor). We compared abundance estimates, model rankings, and coefficient estimates of detection and abundance for white-tailed deer using N-mixture models. AnimalFinder performance varied depending on a threshold value that affects program sensitivity to frequently occurring pixels in a series of images. Higher threshold values led to fewer false negatives (missed deer images) but increased manual processing time, but even at the highest threshold value, the program reduced the images requiring manual review by ~40% and correctly identified >90% of deer, raccoon, and wild pig images. Estimates of white-tailed deer were similar between AnimalFinder and the manual-only method (~1–2 deer difference, depending on the model), as were model rankings and coefficient estimates. Our results show that the program significantly reduced data processing time and may increase efficiency of camera trapping surveys.}
}
@article{riley-1999,
  todo = {}
}
@article{RISC-2019,
  todo = {Resources Information Standards Committee (RISC) (2019) Wildlife camera metadata protocol: standards for components of British Columbia’s biodiversity, no. 44. Knowledge Management Branch, B.C. Ministry of Environment and Climate Change Strategy and B.C. Ministry of Forests, Lands, Natural Resource Operations and Rural Development. Victoria, B.C.}
}
@article{risc-2019,
  todo = {Resources Information Standards Committee (RISC) (2019) Wildlife Camera Metadata Protocol: Standards for Components of British Columbia’s Biodiversity No. 44. Knowledge Management Branch, B.C. Ministry of Environment and Climate Change Strategy and B.C. Ministry of Forests, Lands, Natural Resource Operations and Rural Development. Victoria, B.C}
}
@article{rovero-2010,
  todo = {}
}
@article{rovero-2013,
  todo = {Rovero F, Zimmermann F, Berzi D, Meek P (2013). "Which camera trap type and how many do I need?" A review of camera features and study designs for a range of wildlife research applications. Hystrix, 24, 148–156.}
}
@article{rovero-2016,
  todo = {Camera Trapping for Wildlife Research (Pelagic Pu).}
}
@article{rowcliffe-2008,
  todo = {}
}
@article{rowcliffe-2016,
  todo = {}
}
@article{shannon-2014,
  todo = {}
}
@article{simpson-2014,
  todo = {Simpson R, Page KR, De Roure D (2014) Zooniverse: observing the world's largest citizen science platform. Proceedings of the 23rd International Conference on World Wide Web, 1049-1054. https://doi.org/10.1145/2567948.2579215}
}
@article{sollmann-2012,
  todo = {}
}
@article{swanson-2015,
  todo = {Swanson AA., Kosmala M, Lintott CC, Simpson RR, Smith A, Packer C (2015). Snapshot Serengeti, high-frequency annotated camera trap images of 40 mammalian species in an African savanna. Scientific Data, 2, 150026. https://doi.org/10.1038/sdata.2015.26}
}
@article{soria-2021,
  todo = {Soria CD, Pacifici M, Di Marco M, Stephen SM, Rondinini C (2021) COMBINE: a coalesced mammal database of intrinsic and extrinsic traits. Ecology, 102 (6), e03344.https://doi.org/10.1002/ecy.3344}
}
@article{sun-2021,
  todo = {Sun C, Beirne C, Burgar JM, Howey T, Fisher JT, Burton AC (2021) Simultaneous monitoring of vegetation dynamics and wildlife activity with camera traps to assess habitat change. Remote Sensing in Ecology and Conservation 7(4):666–684. https://doi.org/10.1002/rse2.222}
}
@article{sunarto-2013,
  todo = {}
}
@article{tobias-2022,
  todo = {}
}
@article{tobler-2008,
  todo = {}
}
@article{tobler-2013,
  todo = {}
}
@article{us-vegetation,
  todo = {US National Vegetation Classification, https://usnvc.org}
}
@article{wearn-2013,
  todo = {}
}
@article{wearn-2017,
  todo = {Wearn OR, Glover-Kapfer P (2017) Camera-trapping for conservation: a guide to best practices. WWF Conservation Technology Series 1(1). WWF-UK, Woking, United Kingdom.}
}
@article{weinstein-2018,
  todo = {Weinstein BG (2017) A computer vision for animal ecology. Journal of Animal Ecology, 87 (3), 533-545. https://doi.org/10.1111/1365-2656.12780}
}
@article{wildcam,
  todo = {WildCAM}
}
@article{wildlife-insights,
  todo = {Wildlife Insights (2022). https://www.wildlifeinsights.org/}
}
@article{wildtrax,
  todo = {}
}
@artile{wilkinson-2018,
  todo = {}
}
@article{wilman-2014,
  todo = {Wilman H, Belmaker J, de la Rosa C, Rivandeneira MM, Jetz W (2014). EltonTraits 1.0: Species-level foraging attributes of the world’s birds and mammals. Ecology, 95 (7), 2027-2027. https://doi.org/10.1890/13-1917.1}
}
@article{yang-2017,
  todo = {}
}
@article{yousif-2018,
  title = {Object detection from dynamic scene using joint background modeling and fast deep learning classification},
  author = {Hayder Yousif and Jianhe Yuan and Roland Kays and Zhihai He},
  year = {2018},
  journal = {Journal of Visual Communication and Image Representation},
  volume = {55},
  pages = {802--815},
  doi = {10.1016/j.jvcir.2018.08.013},
  issn = {1047-3203},
  url = {https://www.sciencedirect.com/science/article/pii/S1047320318302013},
  keywords = {Human-animal detection, Camera-trap images, Background subtraction, Deep convolutional neural networks, Wildlife monitoring},
  abstract = {In this paper, we couple effective dynamic background modeling with fast deep learning classification to develop an accurate scheme for human-animal detection from camera-trap images with cluttered moving objects. We introduce a new block-wise background model, named as Minimum Feature Difference (MFD), to model the variation of the background of the camera-trap sequences and generate the foreground object proposals. We then develop a region proposals verification to reduce the number of false alarms. Finally, we perform complexity-accuracy analysis of DCNN to construct a fast deep learning classification scheme to classify these region proposals into three categories: human, animals, and background patches. The optimized DCNN is able to maintain high level of accuracy while reducing the computational complexity by 14 times, which allows near real-time implementation of the proposed method on CPU machines. Our experimental results demonstrate that the proposed method outperforms existing methods on our and Alexander von Humboldt Institute camera-trap datasets in both foreground segmentation and object detection.}
}
@article{young-2018,
  todo = {Young S, Rode-Margono, Amin R (2018) Software to facilitate and streamline camera trap data management: A review. Ecology and Evolution, 8, 9947-9957. https://doi.org/10.1002/ece3.4464}
}
@article{zhao-2005,
  todo = {}
}
